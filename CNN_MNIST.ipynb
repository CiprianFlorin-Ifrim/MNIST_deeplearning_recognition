{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e06b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nReferences: \\n1) https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/\\n2) https://machinelearningmastery.com/visualize-deep-learning-neural-network-model-keras/\\n3) King's College London Keras Instruction Tutorial PDF\\n4) https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "References: \n",
    "1) https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/\n",
    "2) https://machinelearningmastery.com/visualize-deep-learning-neural-network-model-keras/\n",
    "3) King's College London Keras Instruction Tutorial PDF\n",
    "4) https://medium.com/mini-distill/effect-of-batch-size-on-training-dynamics-21c14f7a716e\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4993b1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cipri\\AppData\\Local\\Temp\\ipykernel_28512\\4283796252.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#change width of Jupyer Notebook to use the whole window\n",
    "from IPython.core.display import display, HTML                                    \n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a076ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f85aa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11609564209158597473\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22385000448\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17626220348752568767\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:31:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "]\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4090, compute capability 8.9\n",
      "Compute dtype: float16\n",
      "Variable dtype: float32\n"
     ]
    }
   ],
   "source": [
    "# import libraries to check available training devices\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "# list available devices\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# GPU performance optimisations - only works with XLA devices on non-windows machines\n",
    "tf.function(jit_compile=True)                                   \n",
    "\n",
    "# makes use of the tensor cores available on RTX cards\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# print compute and variable precision \n",
    "print('Compute dtype: %s' % policy.compute_dtype)\n",
    "print('Variable dtype: %s' % policy.variable_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02c62c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and perform split\n",
    "def load_dataset():\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()                   # load dataset\n",
    "    \n",
    "    X_train = X_train.reshape((X_train.shape[0], 28, 28, 1))                   # reshape X_train to have a single channel 28x28 img representation\n",
    "    X_test  = X_test.reshape((X_test.shape[0], 28, 28, 1))                    # reshape X_test to have a single channel 28x28 img representation\n",
    "    \n",
    "    y_train = to_categorical(y_train)                                          # one hot encode train labels\n",
    "    y_test  = to_categorical(y_test)                                           # one hot encode test labels\n",
    "        \n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# process dataset by changing 255 integers to float 0.0-1.0 values\n",
    "def prep_pixels(train, test):\n",
    "    train_float = train.astype('float32') / 255.0                              # normalize to range 0-1\n",
    "    test_float  = test.astype('float32') / 255.0                               # normalize to range 0-1\n",
    "     \n",
    "    return train_float, test_float                                             # return normalized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c7c8ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CNN network\n",
    "def define_cnn():\n",
    "    CNN = Sequential()\n",
    "    CNN.add(Conv2D(32,kernel_size=3,activation='relu',input_shape=(28,28,1)))\n",
    "    CNN.add(BatchNormalization())\n",
    "    CNN.add(Conv2D(32,kernel_size=3,activation='relu'))\n",
    "    CNN.add(BatchNormalization())\n",
    "    CNN.add(Conv2D(32,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "    CNN.add(BatchNormalization())\n",
    "    CNN.add(Dropout(0.4))\n",
    "    \n",
    "    CNN.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "    CNN.add(BatchNormalization())\n",
    "    CNN.add(Conv2D(64,kernel_size=3,activation='relu'))\n",
    "    CNN.add(BatchNormalization())\n",
    "    CNN.add(Conv2D(64,kernel_size=5,strides=2,padding='same',activation='relu'))\n",
    "    CNN.add(BatchNormalization())\n",
    "    CNN.add(Dropout(0.4))\n",
    "    \n",
    "    CNN.add(Flatten())\n",
    "    CNN.add(Dense(128, activation='relu'))\n",
    "    CNN.add(BatchNormalization())\n",
    "    CNN.add(Dropout(0.4))\n",
    "    CNN.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    \n",
    "    # compile model\n",
    "    #optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "    CNN.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    \n",
    "    # return defined cnn\n",
    "    return CNN\n",
    "\n",
    "# train CNN network\n",
    "def train_model(X_train, y_train, X_test, y_test, n_epochs, b_size):\n",
    "    # fit model\n",
    "    cnn_model = define_cnn()                                      \n",
    "    history = cnn_model.fit(X_train, y_train, \n",
    "                            epochs = n_epochs, \n",
    "                            batch_size = b_size, \n",
    "                            validation_data=(X_test, y_test), \n",
    "                            verbose=1)\n",
    "    \n",
    "    return cnn_model, history\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f8a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a model using k-fold cross-validation\n",
    "def evaluate_model(X_data, y_data, n_folds, n_epochs, b_size):\n",
    "    scores, histories = list(), list()\n",
    "    kfold = KFold(n_folds, shuffle = True, random_state = 1)                        # prepare cross validation\n",
    "\n",
    "    for train_ix, test_ix in kfold.split(X_data):                                 # enumerate splits\n",
    "        X_train, y_train = X_data[train_ix], y_data[train_ix]                    # select rows for training\n",
    "        X_test, y_test   = X_data[test_ix], y_data[test_ix]                      # select rows for testing\n",
    "        \n",
    "        cnn_model, history = train_model(X_train, y_train, X_test, y_test, n_folds, n_epochs)\n",
    "\n",
    "        # stores scores\n",
    "        _, acc = cnn_model.evaluate(testX, testY, verbose=0)\n",
    "        print('> %.3f' % (acc * 100.0))\n",
    "        \n",
    "        scores.append(accuracy)\n",
    "        histories.append(history)\n",
    "        \n",
    "    return scores, histories                                                    # return evaluation   \n",
    "    \n",
    "# performance metrics\n",
    "def performance(X_test, y_test, model):\n",
    "        # evaluate model\n",
    "        yhat_probs = model.predict(X_test, verbose=0)                           # predict probabilities for test set\n",
    "        yhat_classes = np.argmax(yhat_probs, axis=1)                             # predict crisp classes for test set \n",
    "        y_test = np.argmax(y_test, axis=1)\n",
    "        \n",
    "        #print(y_test)\n",
    "        #print(yhat_classes)\n",
    "        \n",
    "        # accuracy: (tp + tn) / (p + n)\n",
    "        accuracy = accuracy_score(y_test, yhat_classes)*100\n",
    "        print('Accuracy: %f' % accuracy)\n",
    "        \n",
    "        # precision tp / (tp + fp)\n",
    "        precision = precision_score(y_test, yhat_classes, average = None)*100\n",
    "        print(\"Precision: \", statistics.fmean(precision))\n",
    "        print(\", \".join('{:0.2f}'.format(i) for i in precision))\n",
    "        \n",
    "        # recall: tp / (tp + fn)\n",
    "        recall = recall_score(y_test, yhat_classes, average = None)*100\n",
    "        print(\"Recall: \", statistics.fmean(recall))\n",
    "        print(\", \".join('{:0.2f}'.format(i) for i in recall))\n",
    "        \n",
    "        # f1: 2 tp / (2 tp + fp + fn)\n",
    "        f1 = f1_score(y_test, yhat_classes, average = None)*100\n",
    "        print(\"F1 Score: \", statistics.fmean(f1))\n",
    "        print(\", \".join('{:0.2f}'.format(i) for i in f1))\n",
    "        \n",
    "        # kappa\n",
    "        kappa = cohen_kappa_score(y_test, yhat_classes)*100\n",
    "        print('Cohens kappa: %f' % kappa)\n",
    "        \n",
    "        # confusion matrix\n",
    "        cm = confusion_matrix(y_test, yhat_classes)\n",
    "        labels = (\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\")\n",
    "        cm_plot = ConfusionMatrixDisplay(confusion_matrix=cm, \n",
    "                                         display_labels = labels)\n",
    "        cm_plot.plot()\n",
    "        plt.show()\n",
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    if type(history) == list:\n",
    "        for i in range(len(history)):\n",
    "            # plot loss\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.title('Cross Entropy Loss')\n",
    "            plt.plot(history[i].history['loss'], color='blue', label='train')\n",
    "            plt.plot(history[i].history['val_loss'], color='orange', label='test')\n",
    "\n",
    "            # plot accuracy\n",
    "            plt.subplot(2, 1, 2)\n",
    "            plt.title('Classification Accuracy')\n",
    "            plt.plot(history[i].history['accuracy'], color='blue', label='train')\n",
    "            plt.plot(history[i].history['val_accuracy'], color='orange', label='test')\n",
    "            plt.show()\n",
    "            \n",
    "    else:\n",
    "        # plot loss\n",
    "        plt.subplot(2, 1, 1)\n",
    "        plt.title('Cross Entropy Loss')\n",
    "        plt.plot(history.history['loss'], color='blue', label='train')\n",
    "        plt.plot(history.history['val_loss'], color='orange', label='test')\n",
    "\n",
    "        # plot accuracy\n",
    "        plt.subplot(2, 1, 2)\n",
    "        plt.title('Classification Accuracy')\n",
    "        plt.plot(history.history['accuracy'], color='blue', label='train')\n",
    "        plt.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "        plt.show()\n",
    "        \n",
    "# display performance summary\n",
    "def summarize_performance(scores):\n",
    "    print('Accuracy: mean=%.3f std=%.3f, n=%d' % \n",
    "          (mean(scores)*100, std(scores)*100, len(scores))) \n",
    "    \n",
    "    plt.boxplot(scores)                                                       # box and whisker plots of results\n",
    "    plt.show()                                                                # display results\n",
    "\n",
    "def main_code():\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        EPOCHS  = 40\n",
    "        BATCHES = 16\n",
    "\n",
    "        X_train, y_train, X_test, y_test = load_dataset()                            # load dataset\n",
    "        X_train, X_test = prep_pixels(X_train, X_test)                               # prepare pixel data\n",
    "        #scores, history = evaluate_model(X_train, y_train, 5, EPOCHS, BATCHES)     # evaluate model\n",
    "        #summarize_performance(scores)                                                # summarize estimated performance\n",
    "        cnn_model, history = train_model(X_train, y_train, X_test, y_test, EPOCHS, BATCHES)\n",
    "        performance(X_test, y_test, cnn_model)\n",
    "        summarize_diagnostics(history)                                             # display learning curves\n",
    "        \n",
    "        # release allocated resources after termination\n",
    "        tf.keras.backend.clear_session()\n",
    "        #cuda.select_device(0)\n",
    "        #cuda.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbf9b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "3750/3750 [==============================] - 118s 30ms/step - loss: 0.2019 - accuracy: 0.9397 - val_loss: 0.0428 - val_accuracy: 0.9852\n",
      "Epoch 2/40\n",
      "3750/3750 [==============================] - 112s 30ms/step - loss: 0.0852 - accuracy: 0.9741 - val_loss: 0.0257 - val_accuracy: 0.9911\n",
      "Epoch 3/40\n",
      "3750/3750 [==============================] - 104s 28ms/step - loss: 0.0635 - accuracy: 0.9810 - val_loss: 0.0292 - val_accuracy: 0.9908\n",
      "Epoch 4/40\n",
      "3750/3750 [==============================] - 95s 25ms/step - loss: 0.0558 - accuracy: 0.9839 - val_loss: 0.0197 - val_accuracy: 0.9933\n",
      "Epoch 5/40\n",
      "3750/3750 [==============================] - 98s 26ms/step - loss: 0.0447 - accuracy: 0.9869 - val_loss: 0.0236 - val_accuracy: 0.9922\n",
      "Epoch 6/40\n",
      "3750/3750 [==============================] - 99s 26ms/step - loss: 0.0418 - accuracy: 0.9880 - val_loss: 0.0185 - val_accuracy: 0.9942\n",
      "Epoch 7/40\n",
      "1500/3750 [===========>..................] - ETA: 57s - loss: 0.0342 - accuracy: 0.9900"
     ]
    }
   ],
   "source": [
    "# guard boilerplate\n",
    "if __name__ == \"__main__\":  \n",
    "    main_code()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu-venv",
   "language": "python",
   "name": "gpu-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
